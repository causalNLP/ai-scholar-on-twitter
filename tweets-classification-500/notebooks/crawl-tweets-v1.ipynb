{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["EXA5GotUQ-pl","Ofu3xCu5RLao","M1_DDPWObd4J"],"toc_visible":true,"mount_file_id":"1vHU6DSFHxawWR1qfXVvbSL4VQAso-_-H","authorship_tag":"ABX9TyPZAQxx0X9nLzQLHbTbU+eW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Crawl and preprocess tweets of given users"],"metadata":{"id":"JZDhwT3hz9D5"}},{"cell_type":"markdown","source":["#Imports"],"metadata":{"id":"EXA5GotUQ-pl"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"iFWHLQV2E6CK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1677078708649,"user_tz":-330,"elapsed":14873,"user":{"displayName":"Navreet Kaur","userId":"16808969901099687634"}},"outputId":"541cfb33-577c-4e1e-bec5-c1f9c8b92b41"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting twitter\n","  Downloading twitter-1.19.6-py2.py3-none-any.whl (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.3/50.3 KB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from twitter) (2022.12.7)\n","Installing collected packages: twitter\n","Successfully installed twitter-1.19.6\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tweepy in /usr/local/lib/python3.8/dist-packages (3.10.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from tweepy) (1.3.1)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.8/dist-packages (from tweepy) (1.15.0)\n","Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.8/dist-packages (from tweepy) (2.25.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->tweepy) (3.2.2)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests[socks]>=2.11.1->tweepy) (4.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests[socks]>=2.11.1->tweepy) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests[socks]>=2.11.1->tweepy) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests[socks]>=2.11.1->tweepy) (1.24.3)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.8/dist-packages (from requests[socks]>=2.11.1->tweepy) (1.7.1)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting jsonlines\n","  Downloading jsonlines-3.1.0-py3-none-any.whl (8.6 kB)\n","Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.8/dist-packages (from jsonlines) (22.2.0)\n","Installing collected packages: jsonlines\n","Successfully installed jsonlines-3.1.0\n"]}],"source":["!pip install twitter\n","!pip install tweepy\n","!pip install jsonlines"]},{"cell_type":"code","source":["import tweepy\n","import re\n","from twitter import *\n","import requests\n","import json\n","import csv\n","import jsonlines\n","import time\n","from tqdm import tqdm\n","import numpy as np\n","import pandas as pd\n","import pickle"],"metadata":{"id":"2ysE0h7SE_II"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Setup"],"metadata":{"id":"gLcVJ4lWRDJ9"}},{"cell_type":"code","source":["# API keys \n","api_key = \"\"\n","api_secrets = \"\"\n","bearer_token = \"\"\n","access_token = \"\"\n","access_secret = \"\"\n","\n","# Authenticate to Twitter\n","auth = tweepy.OAuthHandler(api_key,api_secrets)\n","auth.set_access_token(access_token,access_secret)\n"," \n","api = tweepy.API(auth)\n","# api = tweepy.API(auth, wait_on_rate_limit=True, retry_count=10, retry_delay=5, retry_errors=set([503]))\n"," \n","try:\n","    api.verify_credentials()\n","    print('Successful Authentication')\n","except:\n","    print('Failed authentication')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fJzfx2riFAi-","executionInfo":{"status":"ok","timestamp":1677078710330,"user_tz":-330,"elapsed":14,"user":{"displayName":"Navreet Kaur","userId":"16808969901099687634"}},"outputId":"17fe21c1-dbbd-45e2-ebf6-10a33183788e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Successful Authentication\n"]}]},{"cell_type":"code","source":["path = \"/content/drive/My Drive/tweets-dataset/\""],"metadata":{"id":"OODXPLh0FCKA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# df = pd.read_csv(path+'gs_scholars_candidate_twitter_accounts.csv', index_col=0, nrows=501)\n","# df['google_scholar_id'] = df['url'].apply(lambda x : x.split(\"user=\")[1])\n","# df['twitter_id'] = df['url of their twitter'].apply(lambda x : x.split(\".com/\")[-1] if x==x else x)\n","# df[['name', 'google_scholar_id', 'twitter_id']].to_csv(path+\"gs_id2twitter_id.csv\")\n","# df = df[['name', 'google_scholar_id', 'twitter_id']]\n","# df.head()"],"metadata":{"id":"mY0RQwqLKUwq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gs_link_prefix = \"https://scholar.google.com/citations?user=\" \n","twitter_link_prefix = \"https://twitter.com/\""],"metadata":{"id":"jhegRZlMMqth"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Crawl Tweets"],"metadata":{"id":"Ofu3xCu5RLao"}},{"cell_type":"markdown","source":["##### Prev fns"],"metadata":{"id":"M1_DDPWObd4J"}},{"cell_type":"code","source":["# def get_tweets_simple(twitter_name, api):\n","#     try:\n","#         tweets = api.user_timeline(screen_name=twitter_name, count=10, tweet_mode=\"extended\")\n","#         tweets_list = []\n","#         for tweet in tweets:\n","#             json_object = tweet._json\n","#             tweet_info = {\"tweet_id\": json_object[\"id\"], \"num_of_likes\": json_object[\"favorite_count\"],\n","#                           \"text\": json_object[\"full_text\"]}\n","#             # get full text from retweets\n","#             if \"retweeted_status\" in json_object:\n","#                 tweet_info = {\"tweet_id\": json_object[\"id\"], \"num_of_likes\": json_object[\"favorite_count\"],\n","#                               \"text\": json_object[\"retweeted_status\"][\"full_text\"]}\n","#             # change the form of link in the tweets\n","#             urls = re.findall('(?:(?:https?|ftp):\\/\\/)?[\\w/\\-?=%.]+\\.[\\w/\\-&?=%.]+', tweet_info[\"text\"])\n","#             for each in urls:\n","#                 try:\n","#                     r = requests.get(each)\n","#                     tweet_info[\"text\"] = tweet_info[\"text\"].replace(each, r.url)\n","#                 except:\n","#                     continue\n","#             tweets_list.append(tweet_info)\n","#         return tweets_list\n","#     except:\n","#         return None\n","\n","\n","# def get_tweets_simple_qnqq(twitter_name, api):\n","#     try:\n","#         tweets = api.user_timeline(screen_name=twitter_name, count=10, tweet_mode=\"extended\")\n","#         tweets_list = []\n","#         for tweet in tweets:\n","#             json_object = tweet._json\n","#             tweets_list.append(json_object)\n","#         return tweets_list\n","#     except:\n","#         return None\n","\n","# def get_tweets_qnqq(twitter_name, api):\n","#     try:\n","#         tweets = api.user_timeline(screen_name=twitter_name, count=100, tweet_mode=\"extended\")\n","#         tweets_list = []\n","#         for tweet in tweets:\n","#             json_object = tweet._json\n","#             tweets_list.append(json_object)\n","#         return tweets_list\n","#     except:\n","#         return None\n","\n","# def get_tweets(twitter_name, api):\n","#     current_time = time.time()\n","#     try:\n","#         tweets = api.user_timeline(screen_name=twitter_name, count=5, tweet_mode=\"extended\")\n","#         print(f\"time crawing one tweets is {time.time()-current_time}\")\n","#         current_time = time.time()\n","#         tweets_list = []\n","#         for tweet in tweets:\n","#             json_object = tweet._json\n","#             tweet_info = {\"tweet_id\": json_object[\"id\"], \"num_of_likes\": json_object[\"favorite_count\"],\n","#                           \"text\": json_object[\"full_text\"]}\n","#             # get full text from retweets\n","#             if \"retweeted_status\" in json_object:\n","#                 tweet_info = {\"tweet_id\": json_object[\"id\"], \"num_of_likes\": json_object[\"favorite_count\"],\n","#                               \"text\": json_object[\"retweeted_status\"][\"full_text\"]}\n","#             # change the form of link in the tweets\n","#             urls = re.findall('(?:(?:https?|ftp):\\/\\/)?[\\w/\\-?=%.]+\\.[\\w/\\-&?=%.]+', tweet_info[\"text\"])\n","#             for each in urls:\n","#                 try:\n","#                     r = requests.get(each)\n","#                     tweet_info[\"text\"] = tweet_info[\"text\"].replace(each, r.url)\n","#                 except:\n","#                     continue\n","#             tweets_list.append(tweet_info)\n","#         print(f\"time processing one tweets is {time.time()-current_time}\")\n","#         return tweets_list\n","#     except:\n","#         return None\n","\n","# def get_full_tweets(twitter_name, api):\n","#     pass"],"metadata":{"id":"SfIsWhHmM_-m"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[],"metadata":{"id":"rGMD8inE1FT7"}},{"cell_type":"markdown","source":["##### New fns"],"metadata":{"id":"k3YUQQONbhsS"}},{"cell_type":"markdown","source":["\n","Columns in dataset\n","- created_at\n","- id\n","- full_text\n","- user\n","- place\n","- quote_count\n","- reply_count\n","- retweet_count\n","- favorite_count - number of likes\n","- entities\n","- possibly_sensitive\n","- lang\n","- in_reply_to_status_id_str\n","- in_reply_to_user_id_str\n","- in_reply_to_screen_name\n","- is_quote_status\n","- quoted_status_id_str\n","- is_retweet"],"metadata":{"id":"8ZT1zq3QbDjw"}},{"cell_type":"code","source":["def full_text_extractor(tweet):\n","    # if there is 'extended_tweet', return full_text\n","    if tweet.__contains__('extended_tweet'):\n","        return tweet['extended_tweet']['full_text']\n","    # if there is 'retweeted_status' and extended_tweet in it, \n","    # return full_text. Otherwise, return the text.\n","    elif tweet.__contains__('retweeted_status'):\n","        if tweet['retweeted_status'].__contains__('extended_tweet'):\n","            return tweet['retweeted_status']['extended_tweet']['full_text']\n","        else:\n","            return tweet['text']\n","    else:\n","        return tweet['text']\n","\n","def get_rt_full_text(json_object):\n","  return json_object['full_text'][:json_object['full_text'].find(\":\")+2]+json_object['retweeted_status']['full_text']\n","\n","def get_user_info(user_json):\n","  user_fields = [\"id\", \"name\", \"screen_name\", \"location\", \"followers_count\",\\\n","                 \"friends_count\", \"created_at\", \"favourites_count\", \"verified\",\\\n","                 \"statuses_count\", \"lang\", \"profile_image_url\"]\n","  user_info = {}\n","  for field in user_fields:\n","    user_info[field] = user_json[field]\n","  return user_info\n","\n","def get_tweets(twitter_name, api, num_tweets):\n","  try:\n","    tweets = api.user_timeline(screen_name=twitter_name, count=num_tweets, tweet_mode=\"extended\")\n","    tweets_list = []\n","    for i, tweet in enumerate(tweets):\n","      json_object = tweet._json\n","\n","      tweet_info = {\"created_at\": json_object[\"created_at\"],\\\n","                    \"tweet_id\" : json_object[\"id\"], \\\n","                    # \"text\": get_full_text(json_object),\\\n","                    \"text\" : json_object[\"full_text\"], \\\n","                    \"like_count\" : json_object[\"favorite_count\"], \\\n","                    \"quote_count\" : 0,\\\n","                    \"reply_count\" : 0,\\\n","                    \"retweet_count\" : json_object[\"retweet_count\"],\\\n","                    \"user\" : get_user_info(json_object[\"user\"]),\\\n","                    \"place\": json_object[\"place\"],\\\n","                    \"lang\" : json_object[\"lang\"],\\\n","                    \"entities\" : json_object[\"entities\"],\\\n","                    \"possibly_sensitive\" : False,\\\n","                    \"is_quote_status\" : False,\\\n","                    \"in_reply_to_user_id\" : json_object[\"in_reply_to_user_id\"],\\\n","                    \"in_reply_to_screen_name\" : json_object[\"in_reply_to_screen_name\"],\\\n","                    \"is_retweet\" : False\n","                    }\n","      if \"quoted_status_id\" in json_object:\n","        tweet_info[\"is_quote_status\"] = True\n","      if \"quote_count\" in json_object:\n","        tweet_info[\"quote_count\"] =  json_object[\"quote_count\"]\n","      if \"reply_count\" in json_object:\n","        tweet_info[\"reply_count\"] = json_object[\"reply_count\"]\n","      if \"possibly_sensitive\" in json_object:\n","        tweet_info[\"possibly_sensitive\"] = json_object[\"possibly_sensitive\"]\n","      if \"retweeted_status\" in json_object:\n","        tweet_info[\"is_retweet\"] = True\n","        tweet_info[\"text\"] = get_rt_full_text(json_object)\n","      tweets_list.append(tweet_info)\n","    return tweets_list\n","  except:\n","    return None"],"metadata":{"id":"rfY39RBxYmj_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["users = api.search_users(\"Zhijing Jin\")\n","users"],"metadata":{"id":"9Injf-O-d6rR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["api.get_user(\"ZhijingJin\")._json"],"metadata":{"id":"UXaWb1tInxSg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for user in users:\n","  print(user._json['screen_name'])\n","  tweets = get_tweets(user._json['screen_name'], api, 10)\n","  for tweet in tweets:\n","    print(tweet['text'])\n","  print(\"\\n\")"],"metadata":{"id":"cwhsEd3LrPj4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["users[2]._json"],"metadata":{"id":"3oHjWQKHfZWu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["total_tweets = 284176\n","save_dataset = True"],"metadata":{"id":"GqDFAiy5Bedu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open(path+\"/gs_scholars_candidate_twitter_accounts_78k.tsv\",\"r\") as gs_f_r:\n","  reader = csv.reader(gs_f_r, delimiter=\"\\t\")\n","  for i, line in enumerate(reader):\n","    index = line[0]\n","    if i==0:\n","      continue\n","    name = line[1]\n","    candidate_ids = [id for id in line[4:] if len(id)>0]\n","    for rank, c_id in enumerate(candidate_ids):\n","        tweets = get_tweets(c_id, api, 1000)\n","        if tweets is None:\n","          print(index, rank, name, c_id)\n","          continue\n","        total_tweets += len(tweets)\n","        if save_dataset:\n","          with open(path + 'final-dataset-78K/' + str(index) + '_' + str(rank) + '_' + c_id +'.pkl', 'wb') as gs_f_w:\n","            pickle.dump(tweets, gs_f_w)\n","    # time.sleep(1)\n","    if int(index)!=0 and int(index)%50 == 0:\n","      print(f\"Tweets crawled for .. {index}\")"],"metadata":{"id":"INxAoBDSfvRD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["with open(path+\"/gs_scholars_candidate_twitter_accounts.tsv\",\"r\") as f_r:\n","  reader = csv.reader(f_r, delimiter=\"\\t\")\n","  for i, line in enumerate(reader):\n","    index = line[0]\n","    if i==0:\n","      continue\n","    name = line[1]\n","    twitter_url = line[4]\n","    candidate_ids = [id for id in line[6:] if len(id)>0]\n","    for rank, c_id in enumerate(candidate_ids):\n","      # print(index, rank, name, c_id)\n","        tweets = get_tweets(c_id, api, 1000)\n","        if tweets is None:\n","          print(index, rank, name, c_id)\n","          continue\n","        total_tweets += len(tweets)\n","        if save_dataset:\n","          with open(path + 'final-dataset/' + str(index) + '_' + str(rank) + '_' + c_id +'.pkl', 'wb') as f_w:\n","            pickle.dump(tweets, f_w)\n","    time.sleep(1)\n","    if int(index)!=0 and int(index)%50 == 0:\n","      print(f\"Tweets crawled for .. {index}\")"],"metadata":{"id":"mm1ZtAbt0C0F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["total_tweets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fLq9xYJN_yo6","executionInfo":{"status":"ok","timestamp":1676808817181,"user_tz":-330,"elapsed":468,"user":{"displayName":"Navreet Kaur","userId":"16808969901099687634"}},"outputId":"75ae01ed-8218-47e7-91d6-69c20514f737"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["284176"]},"metadata":{},"execution_count":45}]},{"cell_type":"markdown","source":["Number of tweets to crawl per author"],"metadata":{"id":"u8E1e4lhi2PL"}},{"cell_type":"code","source":["max_tweets_per_author = 1000\n","df['twitter_id'].notnull().sum(), df['twitter_id'].notnull().sum()*max_tweets_per_author"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QVSEhTGnicnP","executionInfo":{"status":"ok","timestamp":1674059992145,"user_tz":-330,"elapsed":3,"user":{"displayName":"Navreet Kaur","userId":"16808969901099687634"}},"outputId":"dfeabba0-1961-4d17-a45d-f742b4a6932e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(173, 173000)"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["total_tweets = 0\n","for i, row in df.iterrows():\n","  if row['twitter_id']!=row['twitter_id']:\n","    continue\n","  tweets = get_tweets(row['twitter_id'], api, max_tweets_per_author)\n","  if tweets is None:\n","    print(print(i, row['twitter_id']))\n","    continue\n","  total_tweets += len(tweets)\n","  if save_dataset:\n","    with open(path + 'dataset/' + str(i) + '_' + row['twitter_id'] +'.pkl', 'wb') as f:\n","      pickle.dump(tweets, f)\n","  # time.sleep(1)\n","  if i!=0 and i%50 == 0:\n","    print(\"Tweets crawled for .. \" + str(i))  "],"metadata":{"id":"C7hp29JcQ78a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["total_tweets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CWYqJwfNt34P","executionInfo":{"status":"ok","timestamp":1674060198895,"user_tz":-330,"elapsed":9,"user":{"displayName":"Navreet Kaur","userId":"16808969901099687634"}},"outputId":"fd1c99fb-5f58-4723-dad9-bfab7ee86a04"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["16025"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["from os import listdir\n","from os.path import isfile, join"],"metadata":{"id":"LTjsVLIaUJLN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tweets_dataset = []\n","onlyfiles = [f for f in listdir(path+'dataset/') if isfile(join(path+'/dataset/', f))]\n","for filename in onlyfiles:\n","  tweets_dataset.extend(np.load(path+'/dataset/'+filename, allow_pickle=True))\n","print(len(tweets_dataset))\n","with open(path + 'tweets_500.pkl', 'wb') as f:\n","    pickle.dump(tweets_dataset, f)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g39ppocwvEhg","executionInfo":{"status":"ok","timestamp":1674060299032,"user_tz":-330,"elapsed":1562,"user":{"displayName":"Navreet Kaur","userId":"16808969901099687634"}},"outputId":"4004d516-7233-49dd-8e1d-c1ea0eb0e116"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["16025\n"]}]},{"cell_type":"code","source":["num_retweets = 0\n","for tweet in tweets_dataset:\n","  if tweet['text'][:2] == \"RT\":\n","    num_retweets += 1"],"metadata":{"id":"1blxROnOvFvl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["num_retweets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rqNJAhOLxhtZ","executionInfo":{"status":"ok","timestamp":1674060452683,"user_tz":-330,"elapsed":7,"user":{"displayName":"Navreet Kaur","userId":"16808969901099687634"}},"outputId":"0da06c19-ea94-4cad-a268-17d81406e9d0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["6806"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":["usuable_tweets = total_tweets - num_retweets\n","usuable_tweets"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IVslVHTAx08x","executionInfo":{"status":"ok","timestamp":1674060476245,"user_tz":-330,"elapsed":4,"user":{"displayName":"Navreet Kaur","userId":"16808969901099687634"}},"outputId":"893591a8-df0a-4964-ff6d-2d34b2bee214"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["9219"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["class_0, class_1 = 0, 0\n","popular_names = set()\n","for tweet in tweets_dataset:\n","  if tweet['text'][:2] != \"RT\":\n","    if tweet['like_count'] >= 100:\n","      popular_names.add(tweet['user']['screen_name'])\n","      class_1 += 1\n","    else:\n","      class_0 += 1 "],"metadata":{"id":"IBdjE6wHx6g7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class_0, class_1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6rVr8GIWyXgX","executionInfo":{"status":"ok","timestamp":1674060609480,"user_tz":-330,"elapsed":8,"user":{"displayName":"Navreet Kaur","userId":"16808969901099687634"}},"outputId":"fcecfa07-e06d-42ea-a3f6-e714f3db8968"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(9088, 131)"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["(class_1/usuable_tweets)*100, (class_0/usuable_tweets)*100"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iMqd3ehiybFz","executionInfo":{"status":"ok","timestamp":1674060666393,"user_tz":-330,"elapsed":8,"user":{"displayName":"Navreet Kaur","userId":"16808969901099687634"}},"outputId":"8e1215ab-eb11-494d-b5c6-b8392ddffff4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(1.4209784141447013, 98.5790215858553)"]},"metadata":{},"execution_count":47}]},{"cell_type":"code","source":[],"metadata":{"id":"fDbHKbiFzIMx"},"execution_count":null,"outputs":[]}]}